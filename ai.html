<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Fast Local AI</title>
    <style>
        body { font-family: sans-serif; background: #1a1a1a; color: white; text-align: center; }
        #chat { width: 400px; height: 300px; border: 1px solid #444; margin: 20px auto; overflow-y: auto; padding: 10px; text-align: left; background: #000; }
        #progress-container { width: 400px; background: #333; margin: 10px auto; height: 20px; border-radius: 10px; display: none; }
        #progress-bar { width: 0%; height: 100%; background: #4caf50; border-radius: 10px; transition: width 0.3s; }
        input { width: 320px; padding: 10px; border-radius: 5px; border: none; }
    </style>
</head>
<body>
    <h2>Local AI (Tiny Model)</h2>
    <div id="status">Click "Initialize" to download the model (cached thereafter)</div>
    
    <div id="progress-container"><div id="progress-bar"></div></div>
    
    <div id="chat"></div>
    <input type="text" id="user-input" placeholder="Type here..." disabled>
    <button id="init-btn" onclick="init()">Initialize AI</button>

    <script type="module">
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2';

        let generator;

        window.init = async () => {
            const status = document.getElementById('status');
            const progressContainer = document.getElementById('progress-container');
            const progressBar = document.getElementById('progress-bar');
            const btn = document.getElementById('init-btn');

            btn.style.display = 'none';
            progressContainer.style.display = 'block';
            status.innerText = "Downloading model weights...";

            try {
                // Using the smallest possible version of SmolLM
                generator = await pipeline('text-generation', 'Xenova/SmolLM-135M-Instruct', {
                    progress_callback: (p) => {
                        if (p.status === 'progress') {
                            progressBar.style.width = p.progress + '%';
                        }
                    }
                });

                status.innerText = "AI Ready! Ask me a question.";
                document.getElementById('user-input').disabled = false;
            } catch (e) {
                status.innerText = "Error: " + e.message;
            }
        };

        window.sendChat = async () => {
            const input = document.getElementById('user-input');
            const chat = document.getElementById('chat');
            const text = input.value;
            
            chat.innerHTML += `<div><b>You:</b> ${text}</div>`;
            input.value = '';

            const output = await generator(text, { max_new_tokens: 30 });
            const reply = output[0].generated_text.replace(text, '').trim();
            
            chat.innerHTML += `<div><b>AI:</b> ${reply}</div>`;
            chat.scrollTop = chat.scrollHeight;
        };

        document.getElementById('user-input').addEventListener('keypress', (e) => {
            if(e.key === 'Enter') sendChat();
        });
    </script>
</body>
</html>
